---
title: 多任务学习-02-常见问题
date: 2024-11-30 11:00:00
updated: 2024-12-01 12:00:00
tags: 多任务学习
categories: 算法
---

## 多任务学习可能存在的问题

1. 负迁移（negative transfer）：推荐系统中的任务通常是低相关甚至是相互冲突的，联合训练可能导致性能下降，称之为负迁移

2. 跷跷板现象（seesaw phenomenon），在全部任务中超越单任务模型是非常困难的，指的是在优化一个任务的表现时，往往会导致另一个任务的表现下降，类似于跷跷板一端上升时另一端下降的情况。

## 共享嵌入层的意义

一方面，框架可以利用前几个任务中丰富的正样本来共享信息，缓解后续任务的类不平衡问题；另一方面，可以减少模型参数。

## 常见多任务学习结构

1. 参数硬连接：容易出现“负迁移”的问题
	1. Cross-Stitch Network：深层特征图看作浅层特征图的线性组合，网络的每一层特征图都是上一层多个任务特征图的线性组合
	2. 网络路由：
2. 跷跷板
	1. PLE，把专家分工明确化，然后有一个共享专家
3. ESMM（条件概率迁移）
	1. 主任务是CVR(转化率)
	2. 有标签数据：CTR($P\{Y=1|X\}$)和CTCVR($P\{Z\&Y=1 | X\}$)
		- 通过 $P\{Z\&Y=1 | X\} = P\{Z=1|Y=1, X\}P\{Y=1|X\}$ 联系起来
4. AITM（自适应信息迁移）
	- 详见 `AITM论文笔记`

